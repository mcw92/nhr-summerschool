{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHR Summer School – Data-Parallel Neural Networks with `Pytorch`\n",
    "#### Dr. Charlotte Debus (charlotte.debus@kit.edu), Dr. Marie Weiel (marie.weiel@kit.edu), and David Li (david.li@kit.edu)\n",
    "## Agenda\n",
    "\n",
    "| W H E N           | W H A T                                                 |\n",
    "| :-----------------| :------------------------------------------------------ |\n",
    "| **09:00 - 10:15** | **Introduction to Neural Networks**                     |  \n",
    "|                   | Backpropagation and Stochastic Gradient Descent (SGD)   |  \n",
    "|                   | Layer Architectures                                     |  \n",
    "|                   | Training a Neural Network                               |  \n",
    "| **10:30 - 12:00** | **Hands-on Session: Neural Networks with `PyTorch`**    |  \n",
    "| 12:00 - 13:00     | *Enjoy your lunch break!*                               |  \n",
    "| **13:00 - 14:15** | **Data-Parallel Neural Networks**                       |  \n",
    "|                   | Parallelization Strategies for Neural Networks          |  \n",
    "|                   | Distributed SGD                                         |  \n",
    "|                   | IID and Large Minibatch Effects                         |  \n",
    "| **14:30 - 16:00** | **Hands-on Session: `PyTorch DistributedDataParallel`** |\n",
    "\n",
    "\n",
    "## Hands-on Session: Neural Networks with `Pytorch`\n",
    "In this hands-on tutorial, you will learn how to train a neural network in `Pytorch`. This exercise serves as a prerequisite for training the network in a data-parallel fashion later on. We will use the example of *AlexNet*, a convolutional neural network (CNN) for image classification.\n",
    "\n",
    "### Background and Introduction\n",
    "\n",
    "#### Convolutional Neural Networks \n",
    "\n",
    "In deep learning, CNNs are a class of artificial neural networks most commonly applied to analyze visual images. \n",
    "A CNN consists of one or more convolutional layers, each followed by a so-called pooling layer. In the network, you can repeat this unit as often as you wish. \n",
    "Compared to fully-connected layers, there are three major differences:\n",
    "- 2D or 3D arrangement of neurons\n",
    "- Shared weights\n",
    "- Local connectivity\n",
    "\n",
    "You can find a nice overview of CNNs here: https://www.youtube.com/watch?v=YRhxdVk_sIs&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=19  \n",
    "##### What is a convolutional layer?\n",
    "\n",
    "Usually, the input is a 2D or 3D matrix representing the pixels of a single grayscale or color image sample. The neurons in a convolutional layer are arranged accordingly. \n",
    "Each neuron's input is calculated via a discrete convolution by moving a small convolution matrix, the so-called filter kernel, stepwise over the input. The input corresponds to the inner product of the filter kernel with the currently underlying image section. \n",
    "Neighboring neurons in the convolutional layer thus react to overlapping areas in local environments of the input. \n",
    "Similar to the biological receptive field, a neuron only responds to stimuli in a local neighborhood of the previous layer. \n",
    "The values in the kernel correspond to the weights and are learned independently. \n",
    "They are the same for all neurons of a layer which is why CNNs are translationally invariant. This leads to the fact that, for example, each neuron in the first convolutional layer encodes the intensity of edges in a certain local area of the input.\n",
    "\n",
    "To handle the border regions of the input, various padding methods exist. \n",
    "You can find an overview of zero padding in CNNs here: https://www.youtube.com/watch?v=qSTv_m-KFk0&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=23). \n",
    "\n",
    "After determining each neuron's input as described above, it is transformed into the output by an activation function, for CNNs usually **Re**ctified **L**inear **U**nit, $ReLU\\left(x\\right) = \\text{max}\\left(0,x\\right)$. \n",
    "Since backpropagation requires the computation of gradients, a differentiable approximation of ReLU is used in practice: $f\\left(x\\right)=\\text{ln}\\left(1+e^x\\right)$\n",
    "Such non-linear activations are what create the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
    "\n",
    "##### What is a pooling layer?\n",
    "The subsequent step, pooling, is used to discard unnecessary information. \n",
    "For example, for object recognition in images, an edge's exact position is not important - the approximate location of a feature is sufficient. The biological counterpart to pooling is lateral inhibition in the visual cortex. \n",
    "Different types of pooling exist. By far the most common is max-pooling, where only the activity of the most active neuron is kept from each 2 x 2 square of neurons in the convolutional layer. \n",
    "The remaining neurons' activities are thrown away. Alternatives like mean pooling turned out to be less efficient in practice. \n",
    "Despite the data reduction, the network's performance is generally not reduced; in fact, pooling even offers some significant advantages:\n",
    "\n",
    "- Reduced memory requirements and increased computational speed; thus, the ability to create deeper networks that can solve more complex tasks\n",
    "- Analogously to the visual cortex, automatic growth of the size of the receptive fields (without explicitly increasing the size of the filter kernels) and increasing complexity of recognized features, e.g., parts of a face, in deeper convolutional layers\n",
    "- Prevention of overfitting\n",
    "\n",
    "\n",
    "![Max Pooling.](Max_pooling.png \"Max Pooling with a 2×2 filter and step size = 2. The step size indicates by how many pixels the filter is shifted per operation.\")  \n",
    "\n",
    "Source: By Aphex34 - own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=45673581  \n",
    "Useful overview of max-pooling: https://www.youtube.com/watch?v=ZjM_XQa5s6s&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU&index=24\n",
    "\n",
    "#### AlexNet\n",
    "\n",
    "*AlexNet* is a CNN architecture developed by Alex Krizhevsky together with Ilya Sutskever and Geoffrey Hinton. \n",
    "The network solves the problem of image classification, originally on the ImageNet dataset. \n",
    "The input is an RGB image of size 256 x 256 of one of 1000 classes (e.g., cats, dogs, etc.) and the output is a vector of 1000 numbers that sum up to 1. \n",
    "Thus, the $i^\\text{th}$ element of the output vector can be interpreted as the probability that the input image belongs to the $i^\\text{th}$ class. \n",
    "\n",
    "In the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC), a software competition in image classification, AlexNet achieved a top-5 error of 15.3%, that is more than 10.8% lower than the runner-up. \n",
    "The original work's main finding was that the model's depth is crucial to its high performance, which requires the extensive use of computational resources, but was made possible by training the network on graphics processing units (GPUs).  \n",
    "\n",
    "*AlexNet* consists of eight layers: the first five are convolutional layers, some followed by max-pooling, the last three are fully-connected layers. It uses the non-saturating ReLU activation function, which offers better training performance than the tanh and sigmoid activation functions.\n",
    "*AlexNet* is one of the most influential papers in the field of computer vision, as it provided the impulse for many other papers that used CNNs and GPUs to accelerate deep learning. \n",
    "According to Google Scholar, it has been cited over 131,000 times (as of May 2, 2023). \n",
    "\n",
    "\n",
    "**Imagenet classification with deep convolutional neural networks**\n",
    "\n",
    "Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. *Advances in neural information processing systems* 25 (2012): 1097-1105  \n",
    "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf  \n",
    "\n",
    "*Abstract*  \n",
    "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. \n",
    "On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. \n",
    "The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. \n",
    "To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. \n",
    "To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. \n",
    "We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry. \n",
    "\n",
    "![Architektur von AlexNet.](AlexNet-1.png \"Architecture of AlexNet: AlexNet consists of eight layers: the first five are convolutional layers, some followed by max-pooling layers, the last three are fully connected layers. It uses the non-saturating ReLU activation function.\")  \n",
    "\n",
    "Bildquelle: https://learnopencv.com/understanding-alexnet/\n",
    "\n",
    "#### ImageNet\n",
    "\n",
    "ImageNet (https://image-net.org/index.php) is a database of images released in 2009 at the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) that is used to train CNNs. \n",
    "Each image is associated with a noun. \n",
    "The nouns are arranged hierarchically by the WordNet project. \n",
    "For each noun, there are more than 500 images on average. \n",
    "For more than 14 million images, the objects depicted were documented by hand. \n",
    "In at least one million of the images, these objects are framed. \n",
    "ImageNet contains more than 20,000 categories in English, with typical categories such as \"balloon\" or \"strawberry\". \n",
    "The database of third-party image URL annotations is freely accessible directly through ImageNet, although the actual images are not owned by ImageNet.\n",
    "\n",
    "Since 2010, the ImageNet project has held an annual software competition, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). \n",
    "Here, software systems from the fields of deep learning and object recognition compete to correctly classify and recognize objects and scenes. \n",
    "In this competition, a reduced list of a thousand non-overlapping classes is used.\n",
    "\n",
    "#### CIFAR-10\n",
    "Since the ImageNet dataset is relatively large, we use CIFAR-10 here. \n",
    "This dataset contains 60,000 color images of size 32 x 32 from 10 classes, where each class holds 6000 images. \n",
    "The dataset is divided into five training batches and one test batch, each containing 10,000 images. \n",
    "The test batch contains exactly 1000 randomly selected images from each class. \n",
    "The training batches contain the remaining images in random order, and some training batches may contain more images from one class than others. \n",
    "In total, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Below you can see the classes of the dataset and 10 random images from each class:  \n",
    "![CIFAR-10-Dataset.](Cifar.png \" \")  \n",
    "\n",
    "Source: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "### What you will do now\n",
    "Implement *AlexNet*, along with a sequential training loop, to classify the CIFAR10 dataset in `PyTorch`. \n",
    "Below, you will find \n",
    "\n",
    "- the backbone of the neural network, \n",
    "- some helper functions, and \n",
    "- a function for loading the data.  \n",
    "\n",
    "Complete the code gap text to create functional Python code with all needed class and function definitions as well as the main part. \n",
    "**Normal comments with '#' describe the code as usual, in lines with '##' you have to add code.** \n",
    "\n",
    "### 1. Define your model\n",
    "Neural networks comprise of layers or modules that perform operations on data. \n",
    "`PyTorch`'s `torch.nn` namespace provides all the building blocks you need to build your own neural network [doc](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#). \n",
    "A neural network is a module itself that consists of other modules (layers). \n",
    "This nested structure allows you to build complex architectures easily. \n",
    "Every neural network module in `PyTorch` should subclass the `nn.Module` base class. \n",
    "We thus start with implementing *AlexNet* as a custom model subclass of `nn.Module`. \n",
    "\n",
    "Furthermore, every custom model class in `Pytorch` needs to override the `__init__` and the `forward` method. \n",
    "The network's layers are initialized in `__init__`, which defines our model's architecture by providing type and order of its layers. Operations on the input data are implemented in the `forward` method, which defines the computation performed at every call, i.e., the so-called forward pass.  \n",
    "*Side note: Although the recipe for the forward pass is defined in the* `forward` *method, you should call the* `nn.Module` *instance in your actual code instead. This will take care of running the registered hooks while a plain call of* `model.forward()` *will silently ignore them. Just take this as a technical thing to take into account.* \n",
    "\n",
    "In addition, the `torchvision` package provides popular datasets (such as the CIFAR10 dataset we will use here), model architectures, and common image transformations for computer vision [doc](https://pytorch.org/vision/main/index.html).\n",
    "\n",
    "To define the *AlexNet* model in `__init__`, you will need the following layers as building blocks:\n",
    "- Convolutional layer `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)` [doc](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- ReLU activation function `torch.nn.ReLU()` [doc](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "- Max-pooling layer `torch.nn.MaxPool2d(kernel_size, stride)` [doc](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "- Dropout `torch.nn.Dropout(p)` [doc](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
    "- Fully connected layer `torch.nn.Linear(in_features, out_features)` [doc](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "\n",
    "Last but not least: Always remember, [Google](https://www.google.com) is your best friend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "# Define neural network by subclassing PyTorch's nn.Module. \n",
    "class AlexNet(torch.nn.Module):\n",
    "    \n",
    "    # Initialize neural network layers in __init__. \n",
    "    def __init__(self, num_classes = 1000, dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            # AlexNet has 8 layers: 5 convolutional layers, some followed by max-pooling (see figure),\n",
    "            # and 3 fully connected layers. In this model, we use nn.ReLU between our layers, \n",
    "            # but there are other activations to introduce non-linearity in a model.\n",
    "            # nn.Sequential is an ordered container of modules. \n",
    "            # The data is passed through all the modules in the same order as defined. \n",
    "            # You can use sequential containers to put together a quick network.\n",
    "            #\n",
    "            # IMPLEMENT FEATURE-EXTRACTOR PART OF ALEXNET HERE!\n",
    "            # 1st convolutional layer (+ max-pooling)\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            ## 2nd convolutional layer (+ max-pooling)\n",
    "            ## 3rd + 4th convolutional layer\n",
    "            ## 5th convolutional layer (+ max-pooling)\n",
    "        )\n",
    "        # Average pooling to downscale possibly larger input images.\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = torch.nn.Sequential( \n",
    "            # IMPLEMENT FULLY CONNECTED MULTI-LAYER PERCEPTRON PART HERE!\n",
    "            # 6th, 7th + 8th fully connected layer \n",
    "            # The linear layer is a module that applies a linear transformation \n",
    "            # on the input using its stored weights and biases.\n",
    "            # 6th fully connected layer (+ dropout)\n",
    "            torch.nn.Dropout(p=dropout),\n",
    "            torch.nn.Linear(256 * 6 * 6, 4096),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            ## 7th fully connected layer (+ dropout)\n",
    "            # 8th (output) layer\n",
    "            torch.nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    # Forward pass: Implement operations on the input data, i.e., apply model to input x.\n",
    "    def forward(self, x):\n",
    "        # IMPLEMENT OPERATIONS ON INPUT DATA x HERE!\n",
    "        ## Apply feature-extractor part to input.\n",
    "        ## Apply average-pooling part.\n",
    "        x = torch.flatten(x, 1) # Flatten.\n",
    "        ## Apply fully connected multilayer perceptron part.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define useful helper functions\n",
    "Next, we will define some useful helper functions:\n",
    "- `set_all_seeds`: Set all random seeds to a fixed value. This is important if you want to make your experiments reproducible, which is helpful when debugging code.\n",
    "- `compute_accuracy`: Compute the accuracy of your model's predictions on a given dataset. You will need this function for validating your model during training and for testing it on a held-out test dataset after the training is done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: To run the code on a cluster, it is beneficial to put the helper\n",
    "# functions in a separate module file called, e.g., helper.py and import them via:\n",
    "# from helper import set_all_seeds\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"\n",
    "    Set all seeds to make experiments reproducible.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    seed : int\n",
    "           seed to use\n",
    "    \"\"\"\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed) # seed passed to spawned subprocesses\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return\n",
    "\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Compute accuracy of model predictions on given labeled data.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    model : torch.nn.Module\n",
    "            Model.\n",
    "    data_loader : torch.utils.data.Dataloader\n",
    "                  Dataloader.\n",
    "    device : torch.device\n",
    "             device to use\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float : The model's accuracy on the given dataset in percent.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Disable gradient calculation to reduce memory consumption.\n",
    "\n",
    "        # Initialize number of correctly predicted samples + overall number of samples.\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "            # CONVERT DATASET TO USED DEVICE.\n",
    "            ## features = ...\n",
    "            ## targets = ...\n",
    "            #\n",
    "            # CALCULATE PREDICTIONS OF CURRENT MODEL ON FEATURES OF INPUT DATA.\n",
    "            ## logits = ...\n",
    "            ## Determine class with highest score.\n",
    "            ## Compare predictions to actual labels to determine number of correctly predicted samples.\n",
    "            ## Determine overall number of samples.\n",
    "            \n",
    "    # RETURN ACCURACY AS PERCENTAGE OF CORRECTLY PREDICTED SAMPLES.\n",
    "    ## acc = ...\n",
    "    ## return acc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define dataloaders\n",
    "Next, you need to get the data in somehow. \n",
    "As code for pre-processing data can get messy fast, we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. \n",
    "`PyTorch` provides two data primitives that allow you to use pre-loaded datasets as well as your own data [doc](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html):\n",
    "- `torch.utils.data.Dataset`: Stores the data samples and their corresponding labels (targets).\n",
    "- `torch.utils.data.DataLoader`: Wraps an iterable around the `Dataset` to enable easy access to the samples. \n",
    "\n",
    "As the data does not always come in its final processed form required for training your model, you can use transforms with a `Dataset` to manipulate the data and make it suitable for training. \n",
    "The thus obtained `Dataset` retrieves the dataset's features and labels one sample at a time. \n",
    "However, you have already learned that when training a model, we typically want to pass samples in mini-batches and reshuffle the data at every epoch to reduce model overfitting.\n",
    "`DataLoader` is an iterable that abstracts this complexity for us in an easy API. \n",
    "Simply speaking, it combines the plain dataset with a sampling strategy. \n",
    "We use the CIFAR10 `Dataset` provided by `torchvision` and define the dataloaders for our classification problem below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders_cifar10(batch_size, \n",
    "                            num_workers=0,\n",
    "                            root='data',\n",
    "                            validation_fraction=0.1,\n",
    "                            train_transforms=None,\n",
    "                            test_transforms=None):\n",
    "    \"\"\"\n",
    "    Get CIFAR10 dataloaders for training, validation, and testing.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    batch_size : int\n",
    "                 batch size\n",
    "    num_workers : int\n",
    "                  How many workers to use for data loading.\n",
    "    root : str\n",
    "           path to data dir\n",
    "    validation_fraction : float\n",
    "                          fraction of train dataset used for validation\n",
    "    train_transforms : torchvision.transforms.<transformation>\n",
    "                       How to preprocess the training data.\n",
    "    test_transforms : torchvision.transforms.<transformation>\n",
    "                      How to preprocess the test data.\n",
    "                      \n",
    "    Returns\n",
    "    -------\n",
    "    torch.utils.data.Dataloader : training dataloader\n",
    "    torch.utils.data.Dataloader : validation dataloader\n",
    "    torch.utils.data.Dataloader : testing dataloader   \n",
    "    \"\"\"\n",
    "    if train_transforms is None:\n",
    "        train_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "    if test_transforms is None:\n",
    "        test_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=root,\n",
    "                                                 train=True,\n",
    "                                                 transform=train_transforms,\n",
    "                                                 download=True)\n",
    "\n",
    "    valid_dataset = torchvision.datasets.CIFAR10(root=root,\n",
    "                                                 train=True,\n",
    "                                                 transform=test_transforms)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=root,\n",
    "                                                train=False,\n",
    "                                                transform=test_transforms)\n",
    "\n",
    "    # Perform index-based train-validation split of original training data. \n",
    "    total = len(train_dataset) # Get overall number of samples in original training data.\n",
    "    idx = list(range(total)) # Make index list.\n",
    "    np.random.shuffle(idx) # Shuffle indices.\n",
    "    vnum = int(validation_fraction * total) # Determine number of validation samples from validation split.\n",
    "    train_indices, valid_indices = idx[vnum:], idx[0:vnum] # Extract train and validation indices.\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               sampler=valid_sampler)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=num_workers,\n",
    "                                               drop_last=True,\n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_workers=num_workers,\n",
    "                                              shuffle=False)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define the training loop\n",
    "Now that we have our `AlexNet` model and the CIFAR10 data, we want to actually train, validate, and test it by optimizing its parameters on our data. \n",
    "When training neural networks, the most frequently used algorithm is backpropagation, where the parameters, or model weights, are adjusted according to the gradient of the loss function with respect to the given parameter. \n",
    "To compute those gradients automatically, `PyTorch` has a built-in differentiation engine called `torch.autograd`. \n",
    "Training a model is an iterative process. In each iteration, the model predicts the output for a given input, calculates the error in its prediction as quantified by the loss function, collects the derivatives of the loss w.r.t. its parameters, and optimizes these parameters using gradient descent. \n",
    "For a more detailed walkthrough of this process, check out this video on backpropagation from [3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8).\n",
    "\n",
    "The training is influenced by adjustable hyperparameters (HPs) that let you control the model optimization process.\n",
    "Before training your model, you need to set the following HPs:\n",
    "- **Number of epochs:** How many times to iterate over the complete dataset.\n",
    "- **Batch size:** How many data samples to propagate through the network before updating the parameters.\n",
    "- **Learning rate (LR):** How much to change the model parameters at each update step. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
    "\n",
    "Once you set these HPs, you can train and optimize your model within an optimization loop, where each iteration is an epoch consisting of two main parts:\n",
    "- **Training loop:** Iterate over the mini-batched training dataset and try to converge to optimal parameters.\n",
    "- **Validation loop:** Iterate over the validation dataset to check if the model's performance is improving on unseen data.\n",
    "\n",
    "The most important concepts used in the training loop are explained in more detail below. \n",
    "If you are already familiar with these things, you can just skip those parts.\n",
    "\n",
    "##### Loss function\n",
    "When presented with some training data, an untrained network is unlikely to give the correct answer. \n",
    "We use a loss function to measure the degree of dissimilarity of a prediction to the actual target, and it is the loss function that we want to minimize during training. \n",
    "To calculate the loss, we make a prediction using the inputs of our given data sample and somehow compare it with the true data label value. \n",
    "A common loss function for classification is cross entropy, which normalizes the logits and computes the prediction error.\n",
    "\n",
    "##### Optimizer\n",
    "Optimization is the process of adjusting the model's parameters to reduce the model error in each training step. Optimization algorithms define how this process is performed. \n",
    "The `torch.optim` package provides various optimization algorithms [doc](https://pytorch.org/docs/stable/optim.html). \n",
    "To use `torch.optim`, you have to construct an `optimizer` object that encapsulates all optimization logic. \n",
    "We initialize the `optimizer` by registering the model’s parameters that need to be trained and passing it the LR hyperparameter.\n",
    "During the training, this `optimizer` will hold the current state and update the parameters based on the computed gradients. \n",
    "\n",
    "Here, we use stochastic gradient descent, `torch.optim.SGD`. Additionally, many different optimizers are available in `PyTorch`, such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
    "\n",
    "##### Training loop\n",
    "Inside the training loop, optimization technically happens in three steps:\n",
    "- Call `optimizer.zero_grad()` to reset the gradients of your model's parameters before processing a new mini-batch. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "- Backpropagate the prediction loss with a call to `loss.backward()`. `PyTorch` deposits the gradients of the loss w.r.t. each parameter. \n",
    "- Once we have our gradients, call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass.\n",
    "\n",
    "##### Adjust the learning rate\n",
    "When training deep neural networks, it is often useful to reduce the LR as the training progresses. \n",
    "So-called learning rate schedulers adjust the LR during training by reducing it according to a pre-defined schedule. \n",
    "`torch.optim.lr_scheduler` provides several methods to do so based on the number of epochs. \n",
    "For example, `torch.optim.lr_scheduler.ReduceLROnPlateau` allows dynamic LR reducing based on some validation measurements, like the model's accuracy on the validation dataset.\n",
    "LR scheduling should be applied after the optimizer's update at the end of each epoch.\n",
    "\n",
    "We define all of this functionality in the `train_model` function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader,\n",
    "                valid_loader, test_loader, optimizer,\n",
    "                device, logging_interval=50,\n",
    "                scheduler=None):\n",
    "    \"\"\"\n",
    "    Train your model.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    model : torch.nn.Module\n",
    "            model to train\n",
    "    num_epochs : int\n",
    "                 number of epochs to train\n",
    "    train_loader : torch.utils.data.Dataloader\n",
    "                   training dataloader\n",
    "    valid_loader : torch.utils.data.Dataloader\n",
    "                   validation dataloader\n",
    "    test_loader : torch.utils.data.Dataloader\n",
    "                  testing dataloader\n",
    "    optimizer : torch.optim.Optimizer\n",
    "                optimizer to use\n",
    "    device : torch.device\n",
    "             device to train on\n",
    "    logging_interval : int\n",
    "                       logging interval\n",
    "    scheduler : torch.optim.lr_scheduler.<scheduler>\n",
    "                optional learning rate scheduler\n",
    "                \n",
    "    Returns\n",
    "    -------\n",
    "    [float] : loss history\n",
    "    [float] : training accuracy history\n",
    "    [float] : validation accuracy history\n",
    "    \"\"\"\n",
    "    ## start = ... # Start timer to measure training time.\n",
    "\n",
    "    # Initialize history lists for loss, training accuracy, and validation accuracy.\n",
    "    loss_history, train_acc_history, valid_acc_history = [], [], []\n",
    "\n",
    "    # ACTUAL TRAINING STARTS HERE.    \n",
    "    for epoch in range(num_epochs): # Loop over epochs.\n",
    "\n",
    "        # IMPLEMENT TRAINING LOOP HERE.\n",
    "        #\n",
    "        ## Set model to training mode.\n",
    "        #  Thus, layers like dropout which behave differently on train and  \n",
    "        #  test procedures know what is going on and can behave accordingly. \n",
    "        \n",
    "        for batch_idx, (features, targets) in enumerate(train_loader): # Loop over mini batches.\n",
    "\n",
    "            # CONVERT DATASET TO USED DEVICE.\n",
    "            ## features = ...\n",
    "            ## targets = ...\n",
    "            #\n",
    "            # FORWARD & BACKWARD PASS\n",
    "            ## logits = ... # Get predictions of model with current parameters.\n",
    "            ## loss = ...   # Calculate cross-entropy loss on current mini-batch.\n",
    "            ## Zero out gradients.\n",
    "            ## Backward pass on loss.\n",
    "            ## Perform single optimization step to update model parameters via optimizer.\n",
    "            #\n",
    "            # LOGGING\n",
    "            ## Append loss to history list.\n",
    "            \n",
    "            if not batch_idx % logging_interval:\n",
    "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
    "                      f'| Loss: {loss:.4f}')\n",
    "\n",
    "        # VALIDATION STARTS HERE.\n",
    "        #\n",
    "        ## Set model to evaluation mode.\n",
    "        \n",
    "        with torch.no_grad(): # Disable gradient calculation to reduce memory consumption.\n",
    "            \n",
    "            # COMPUTE ACCURACY OF CURRENT MODEL PREDICTIONS ON TRAINING + VALIDATION DATASETS.\n",
    "            ## train_acc = compute_accuracy(...)\n",
    "            ## valid_acc = compute_accuracy(...)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                  f'| Train: {train_acc :.2f}% '\n",
    "                  f'| Validation: {valid_acc :.2f}%')\n",
    "            \n",
    "            ## APPEND ACCURACY VALUES TO CORRESPONDING HISTORY LISTS.\n",
    "            \n",
    "        ## elapsed = ... # Stop timer and calculate training time elapsed after epoch.\n",
    "        ## Print training time elapsed after epoch.\n",
    "        \n",
    "        if scheduler is not None: \n",
    "            scheduler.step(valid_acc_history[-1])\n",
    "        \n",
    "    ## elapsed = ... # Stop timer and calculate total training time.\n",
    "    ## Print overall training time.\n",
    "    \n",
    "    # FINAL TESTING STARTS HERE.\n",
    "    #\n",
    "    ## test_acc = compute_accuracy(...) # Compute accuracy on test data.\n",
    "    ## Print test accuracy.\n",
    "\n",
    "    ## Return history lists for loss, training accuracy, and validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. General settings before we are good to go\n",
    "Before training your model in the actual main script, you need to make some general settings, like choosing a random seed and the training HPs. \n",
    "As we want to train our model on a hardware accelerator, i.e., a GPU, we first check if `torch.cuda` is available, otherwise we use the CPU. \n",
    "For reproducibility, we set all seeds to a fixed value `seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "seed = 123 # random seed.\n",
    "e = 100    # number of epochs\n",
    "b = 256    # batch size\n",
    "lr = 0.1   # learning rate\n",
    "\n",
    "# Get device used for training, e.g., check via torch.cuda.is_available().\n",
    "## device = ...\n",
    "## Print used device.\n",
    "## Set all seeds to chosen random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load the data\n",
    "We define some transforms for data preprocessing and use our dataloader function `get_dataloaders_cifar10` from above to load the data. \n",
    "As *AlexNet* was originally intended for classification of the 256 x 256 RGB images in the ImageNet dataset, we need to make some adjustments to make the very same architecture work for classification of the smaller RGB images in the CIFAR10 dataset. \n",
    "If you'd use the original 32 x 32 CIFAR10 images as inputs, your samples would disappear at the last convolutional layer. \n",
    "To fix this problem, you can upsample the CIFAR10 samples to 64 x 64 pixels before passing them as inputs to *AlexNet*. \n",
    "This is what is done in the transforms below, among other things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "86.8%"
     ]
    }
   ],
   "source": [
    "# DATASET\n",
    "# Transforms on your data allow you to take it from its source state and transform it into ready-for-training data.\n",
    "\n",
    "# Transforms applied to training data (randomness to make network more robust against overfitting)\n",
    "train_transforms = torchvision.transforms.Compose([ # Compose several transforms together.\n",
    "    torchvision.transforms.Resize((70, 70)), # Upsample CIFAR-10 images to make them work with AlexNet.\n",
    "    torchvision.transforms.RandomCrop((64, 64)), # Randomly crop image to make NN more robust against overfitting.\n",
    "    torchvision.transforms.ToTensor(), # Convert image into torch tensor.\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalize to [-1,1] via (image-mean)/std.\n",
    "                                      ])\n",
    "# Transforms applied to validation and test data (no randomness for actual predictions!)\n",
    "test_transforms = torchvision.transforms.Compose([ # Compose several transforms together.\n",
    "    torchvision.transforms.Resize((70, 70)), # Upsample CIFAR-10 images to make them work with AlexNet.\n",
    "    torchvision.transforms.CenterCrop((64, 64)), # Crop images centrally.      \n",
    "    torchvision.transforms.ToTensor(), # Convert image to torch tensor.     \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize to [-1,1] via (image-mean)/std.\n",
    "\n",
    "# GET PYTORCH DATALOADERS FOR TRAINING, TESTING, AND VALIDATION DATASET.\n",
    "## train_loader, valid_loader, test_loader = get_dataloaders_cifar10(...)\n",
    "\n",
    "# Check loaded dataset.\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Set up your model and train it\n",
    "We create an instance of `AlexNet`, move it to the `device`, and print its structure. \n",
    "Remember that to use a model, we just pass it the input data. This executes the model's `forward` method, along with some background operations. Do not call `model.forward()` directly!\n",
    "Furthermore, we set up an `optimizer` and `scheduler` instance as described above.\n",
    "To start the training, we call our `train_model` function and pass it the model, the training HPs, the dataloaders, the optimizer, and the scheduler objects as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model = ... # Build instance of AlexNet with 10 classes for CIFAR-10 and convert it to used device.\n",
    "## Print model.\n",
    "\n",
    "# Set up stochastic gradient descent optimizer using torch.optim package.\n",
    "# Use a momentum of 0.9 and a learning rate of 0.1.\n",
    "## optimizer = ... \n",
    "\n",
    "# Set up LR scheduler.     \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True)\n",
    "\n",
    "# TRAIN MODEL.\n",
    "## loss_list, train_acc_list, valid_acc_list = train_model(...)\n",
    "\n",
    "# Save history lists for loss, training accuracy, and validation accuracy to files.\n",
    "torch.save(loss_list, 'loss.pt')\n",
    "torch.save(train_acc_list, 'train_acc.pt')\n",
    "torch.save(valid_acc_list, 'valid_acc.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations! \n",
    "You have successfully trained a deep neural network in `PyTorch`. To analyze your results visually, you can now plot the evolution of the loss, training accuracy, and validation accuracy over the training, e.g., with `matplotlib.pyplot`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
